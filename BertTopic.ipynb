{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from BertTM import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', )\n",
    "model = BertForSequenceClassificationOutputPooled.from_pretrained('bert-base-uncased', \n",
    "                                                              output_attentions=True, \n",
    "                                                              output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../bert-classifier-pytorch/model_save_attention_1epoch\"\n",
    "\n",
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "model = BertForSequenceClassificationOutputPooled.from_pretrained(output_dir,\n",
    "                                                      output_attentions = True, \n",
    "                                                      output_hidden_states = True)\n",
    "tokenizer = BertTokenizer.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "token_list = []\n",
    "cls_ = '[CLS]'\n",
    "sep_ = '[SEP]'\n",
    "sentences = ['Hello, my dog is cute and cutest.', 'I am too']\n",
    "for i, sent in enumerate(sentences):\n",
    "    inputs = tokenizer.encode_plus(sentences[i], add_special_tokens=True)\n",
    "    tokens = [cls_] + tokenizer.tokenize(sentences[i]) + [sep_]\n",
    "    input_ids = torch.tensor(inputs['input_ids']).unsqueeze(0)\n",
    "    input_list.append(input_ids)\n",
    "    token_list.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sentence embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_model = models.BERT(output_dir, max_seq_length = 240,)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "st_model = SentenceTransformer(modules=[word_embedding_model, pooling_model],\n",
    "                               #device=torch.device(\"cuda\")\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test that attention and vectorization work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentions = get_attention(sentences, model, tokenizer, method = 'first')\n",
    "np.sum([tpl[1] for tpl in attentions[1]])\n",
    "\n",
    "vectorized = vectorize(sentences, model, tokenizer)\n",
    "torch.stack(vectorized).detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('this', 0.0613682),\n",
       "  ('movie', 0.030429687),\n",
       "  ('was', 0.035641603),\n",
       "  ('the', 0.21911351),\n",
       "  ('cutest', 0.06270852),\n",
       "  ('.', 0.09440403),\n",
       "  ('read', 0.0423442),\n",
       "  ('more', 0.06480052),\n",
       "  ('at', 0.06262489),\n",
       "  ('http', 0.027938599),\n",
       "  (':', 0.043154325),\n",
       "  ('/', 0.038011733),\n",
       "  ('/', 0.041409045),\n",
       "  ('worstever', 0.04187157),\n",
       "  ('.', 0.08471608),\n",
       "  ('com', 0.049463503)]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_attention([\"this movie was the cutest. read more at http://worstever.com\"], model, tokenizer, method = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Model from BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nlwx_2020_hashtags_no_rt_predictions.csv\")\n",
    "data = df['text']\n",
    "ngram = (1, 3)\n",
    "n_topics = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 rows in 0.15 seconds.\n",
      "Processed 500 rows in 98.27 seconds.\n",
      "Processed 1000 rows in 193.77 seconds.\n",
      "Processed 1500 rows in 290.81 seconds.\n",
      "Processed 2000 rows in 386.74 seconds.\n",
      "Processed 2500 rows in 484.5 seconds.\n",
      "Processed 3000 rows in 584.24 seconds.\n",
      "Processed 3500 rows in 679.84 seconds.\n",
      "Processed 4000 rows in 776.88 seconds.\n",
      "Processed 4500 rows in 873.04 seconds.\n",
      "Processed 5000 rows in 969.55 seconds.\n",
      "Processed 5500 rows in 1067.45 seconds.\n",
      "Processed 6000 rows in 1168.92 seconds.\n",
      "Processed 6500 rows in 1268.35 seconds.\n",
      "Processed 7000 rows in 1366.79 seconds.\n",
      "Processed 7500 rows in 1468.06 seconds.\n",
      "Processed 8000 rows in 1570.23 seconds.\n",
      "Processed 8500 rows in 1671.15 seconds.\n",
      "Processed 9000 rows in 1772.01 seconds.\n",
      "Processed 9500 rows in 1872.32 seconds.\n",
      "Processed 10000 rows in 1970.01 seconds.\n",
      "Processed 10500 rows in 2071.37 seconds.\n",
      "Processed 11000 rows in 2172.99 seconds.\n",
      "Processed 11500 rows in 2273.16 seconds.\n",
      "Processed 12000 rows in 2370.85 seconds.\n",
      "Processed 12500 rows in 2469.11 seconds.\n",
      "Processed 13000 rows in 2567.32 seconds.\n",
      "Processed 13500 rows in 2668.98 seconds.\n",
      "Processed 14000 rows in 2772.43 seconds.\n",
      "Processed 14500 rows in 2876.16 seconds.\n",
      "Processed 15000 rows in 2975.96 seconds.\n",
      "Processed 15500 rows in 3077.56 seconds.\n",
      "Processed 16000 rows in 3179.27 seconds.\n",
      "Processed 16500 rows in 3279.89 seconds.\n",
      "Processed 17000 rows in 3381.93 seconds.\n",
      "Processed 17500 rows in 3483.49 seconds.\n",
      "Processed 18000 rows in 3584.39 seconds.\n",
      "Processed 18500 rows in 3688.12 seconds.\n",
      "Processed 19000 rows in 3790.6 seconds.\n",
      "Processed 19500 rows in 3891.36 seconds.\n",
      "Processed 20000 rows in 3987.45 seconds.\n",
      "Processed 20500 rows in 4084.35 seconds.\n",
      "Processed 21000 rows in 4185.52 seconds.\n",
      "Processed 21500 rows in 4286.16 seconds.\n",
      "CPU times: user 1h 11min 51s, sys: 28.7 s, total: 1h 12min 20s\n",
      "Wall time: 1h 12min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rows, attentions = get_embeddings(data, model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data after creating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_data = []\n",
    "\n",
    "for i in range(len(rows)):\n",
    "    all_model_data.append((data[i], df.prediction[i], attentions[i], rows[i]))\n",
    "    \n",
    "#pickle.dump(all_model_data, open(f\"attentions_sent_embeddings.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312\n"
     ]
    }
   ],
   "source": [
    "hashtags = ['nlwhiteout', 'nlweather', 'newfoundland', 'nlblizzard2020', 'nlstorm2020',\n",
    " 'snowmaggedon2020', 'stormageddon2020', 'snowpocalypse2020', 'snowmageddon',\n",
    " 'nlstorm', 'nltraffic', 'nlwx', 'nlblizzard']\n",
    "def get_stopwords(hashtags = [], filename = 'stopwords-en.json'):\n",
    "    with open(filename) as fopen:\n",
    "        stopwords = json.load(fopen)\n",
    "\n",
    "    stopwords.extend(['#', '@', '…', \"'\", \"’\", \"[UNK]\", \"\\\"\", \";\", \"*\", \"_\", \"amp\", \"&\", \"“\", \"”\"] + hashtags)\n",
    "    return(stopwords)\n",
    "\n",
    "\n",
    "stopwords = get_stopwords()\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pickled embedding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_data = pickle.load(open(\"attentions_sent_embeddings.pkl\", \"rb\"))\n",
    "texts, _, attentions, rows = zip(*all_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train kmeans model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting kmeans model.\n",
      "The number of texts per label are:\n",
      "{0: 2632, 1: 4438, 2: 1034, 3: 826, 4: 670, 5: 798, 6: 2858, 7: 4467, 8: 4074}\n",
      "CPU times: user 41.7 s, sys: 1.81 s, total: 43.5 s\n",
      "Wall time: 37.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "labels = get_clusters(rows, n_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop stopwords and empty documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering attentions.\n",
      "CPU times: user 13.8 s, sys: 4 ms, total: 13.8 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "  \n",
    "filtered_a, filtered_t, filtered_l = filter_data(attentions, stopwords, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Gensim's phraser to determine which ngram to include a word in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.28 s, sys: 8 ms, total: 5.29 s\n",
      "Wall time: 5.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "features = get_phrases(filtered_t, min_count=10, threshold=0.5)\n",
    "pickle.dump(features, open('features.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use BERT's attention mechanism to determine which words characterize each kmeans cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Determining cluster components. This will take awhile. \n",
      "Progress will be printed for every 500th processed property.\n",
      "    \n",
      "Processed 5000 texts in 1.99 seconds.\n",
      "Processed 10000 texts in 3.99 seconds.\n",
      "Processed 15000 texts in 6.09 seconds.\n",
      "Processed 20000 texts in 8.26 seconds.\n",
      "Finished determining a total of 21797 cluster components. Total time 8.97 seconds.\n",
      "CPU times: user 8.99 s, sys: 0 ns, total: 8.99 s\n",
      "Wall time: 8.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "components, words_label = determine_cluster_components(filtered_l, filtered_a, ngram, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use term frequency inverse cluster frequency with and without BERT's attentions mechanism to determine which words characterize each kmeans cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 304 ms, sys: 0 ns, total: 304 ms\n",
      "Wall time: 305 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_indexed = tf_icf(words_label, n_topics)\n",
    "components_tfidf, components_tfidf_attn = get_tfidf_components(components, tfidf_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic 0</th>\n",
       "      <th>topic 1</th>\n",
       "      <th>topic 2</th>\n",
       "      <th>topic 3</th>\n",
       "      <th>topic 4</th>\n",
       "      <th>topic 5</th>\n",
       "      <th>topic 6</th>\n",
       "      <th>topic 7</th>\n",
       "      <th>topic 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snow</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>power</td>\n",
       "      <td>assistance</td>\n",
       "      <td>hope</td>\n",
       "      <td>stay safe</td>\n",
       "      <td>snow</td>\n",
       "      <td>snow</td>\n",
       "      <td>newfoundland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>storm</td>\n",
       "      <td>nlwx</td>\n",
       "      <td>closed</td>\n",
       "      <td>helping</td>\n",
       "      <td>hoping</td>\n",
       "      <td>safe</td>\n",
       "      <td>storm</td>\n",
       "      <td>stormageddon2020</td>\n",
       "      <td>snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stormageddon2020</td>\n",
       "      <td>nlblizzard2020</td>\n",
       "      <td>power outage</td>\n",
       "      <td>support</td>\n",
       "      <td>thinking</td>\n",
       "      <td>warning</td>\n",
       "      <td>people</td>\n",
       "      <td>storm</td>\n",
       "      <td>storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emergency</td>\n",
       "      <td>snow</td>\n",
       "      <td>road</td>\n",
       "      <td>people</td>\n",
       "      <td>stay safe</td>\n",
       "      <td>storm</td>\n",
       "      <td>power</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>nlwx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wind</td>\n",
       "      <td>snowmaggedon2020</td>\n",
       "      <td>snow</td>\n",
       "      <td>emergency</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>stay</td>\n",
       "      <td>car</td>\n",
       "      <td>snowmaggedon2020</td>\n",
       "      <td>shovel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>newfoundland</td>\n",
       "      <td>nlstorm</td>\n",
       "      <td>storm</td>\n",
       "      <td>supply</td>\n",
       "      <td>prayer</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>digging</td>\n",
       "      <td>blizzard</td>\n",
       "      <td>snowmaggedon2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blizzard</td>\n",
       "      <td>nlstorm2020</td>\n",
       "      <td>emergency</td>\n",
       "      <td>community</td>\n",
       "      <td>safe</td>\n",
       "      <td>emergency</td>\n",
       "      <td>missing</td>\n",
       "      <td>snowstorm</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weather</td>\n",
       "      <td>nltraffic</td>\n",
       "      <td>lost power</td>\n",
       "      <td>food</td>\n",
       "      <td>god</td>\n",
       "      <td>envcanada advisory blowingsnow</td>\n",
       "      <td>stuck</td>\n",
       "      <td>weather</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>snowfall</td>\n",
       "      <td>snowmageddon</td>\n",
       "      <td>outage</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>storm</td>\n",
       "      <td>alert</td>\n",
       "      <td>emergency</td>\n",
       "      <td>winter</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>update</td>\n",
       "      <td>snowstorm</td>\n",
       "      <td>damage</td>\n",
       "      <td>service</td>\n",
       "      <td>hope safe</td>\n",
       "      <td>blizzard warning</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>snowpocalypse2020</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            topic 0           topic 1       topic 2       topic 3  \\\n",
       "0              snow      newfoundland         power    assistance   \n",
       "1             storm              nlwx        closed       helping   \n",
       "2  stormageddon2020    nlblizzard2020  power outage       support   \n",
       "3         emergency              snow          road        people   \n",
       "4              wind  snowmaggedon2020          snow     emergency   \n",
       "5      newfoundland           nlstorm         storm        supply   \n",
       "6          blizzard       nlstorm2020     emergency     community   \n",
       "7           weather         nltraffic    lost power          food   \n",
       "8          snowfall      snowmageddon        outage  newfoundland   \n",
       "9            update         snowstorm        damage       service   \n",
       "\n",
       "        topic 4                         topic 5       topic 6  \\\n",
       "0          hope                       stay safe          snow   \n",
       "1        hoping                            safe         storm   \n",
       "2      thinking                         warning        people   \n",
       "3     stay safe                           storm         power   \n",
       "4  newfoundland                            stay           car   \n",
       "5        prayer                    newfoundland       digging   \n",
       "6          safe                       emergency       missing   \n",
       "7           god  envcanada advisory blowingsnow         stuck   \n",
       "8         storm                           alert     emergency   \n",
       "9     hope safe                blizzard warning  newfoundland   \n",
       "\n",
       "             topic 7           topic 8  \n",
       "0               snow      newfoundland  \n",
       "1   stormageddon2020              snow  \n",
       "2              storm             storm  \n",
       "3       newfoundland              nlwx  \n",
       "4   snowmaggedon2020            shovel  \n",
       "5           blizzard  snowmaggedon2020  \n",
       "6          snowstorm            people  \n",
       "7            weather              love  \n",
       "8             winter              hope  \n",
       "9  snowpocalypse2020               day  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_attn = topics_df(\n",
    "    topics = n_topics,\n",
    "    components = components,\n",
    "    n_words = 10)\n",
    "\n",
    "pickle.dump(topics_attn, open(\"topics_sent_embed_attn.pickle\", \"wb\"))\n",
    "topics_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic 0</th>\n",
       "      <th>topic 1</th>\n",
       "      <th>topic 2</th>\n",
       "      <th>topic 3</th>\n",
       "      <th>topic 4</th>\n",
       "      <th>topic 5</th>\n",
       "      <th>topic 6</th>\n",
       "      <th>topic 7</th>\n",
       "      <th>topic 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nlwx</td>\n",
       "      <td>nlwx</td>\n",
       "      <td>power</td>\n",
       "      <td>assistance</td>\n",
       "      <td>prayer</td>\n",
       "      <td>stay safe</td>\n",
       "      <td>nlwx</td>\n",
       "      <td>nlwx</td>\n",
       "      <td>nlwx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>snow</td>\n",
       "      <td>nlblizzard2020</td>\n",
       "      <td>road</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>hope</td>\n",
       "      <td>nlwx</td>\n",
       "      <td>snow</td>\n",
       "      <td>snow</td>\n",
       "      <td>newfoundland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newfoundland</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>nlwx</td>\n",
       "      <td>people</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>car</td>\n",
       "      <td>snowmaggedon2020</td>\n",
       "      <td>snowmaggedon2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>storm</td>\n",
       "      <td>snowmaggedon2020</td>\n",
       "      <td>power outage</td>\n",
       "      <td>emergency</td>\n",
       "      <td>nlblizzard2020</td>\n",
       "      <td>safe</td>\n",
       "      <td>people</td>\n",
       "      <td>stormageddon2020</td>\n",
       "      <td>nlblizzard2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wind</td>\n",
       "      <td>nltraffic</td>\n",
       "      <td>john</td>\n",
       "      <td>nlwx</td>\n",
       "      <td>stay safe</td>\n",
       "      <td>storm</td>\n",
       "      <td>house</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>emergency</td>\n",
       "      <td>nlstorm2020</td>\n",
       "      <td>snow</td>\n",
       "      <td>helping</td>\n",
       "      <td>thinking</td>\n",
       "      <td>blizzard warning</td>\n",
       "      <td>john</td>\n",
       "      <td>storm</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stormageddon2020</td>\n",
       "      <td>snowmageddon</td>\n",
       "      <td>emergency</td>\n",
       "      <td>support</td>\n",
       "      <td>safe</td>\n",
       "      <td>envcanada advisory blowingsnow</td>\n",
       "      <td>road</td>\n",
       "      <td>nlblizzard2020</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>john</td>\n",
       "      <td>snow</td>\n",
       "      <td>closed</td>\n",
       "      <td>community</td>\n",
       "      <td>hope safe</td>\n",
       "      <td>nlblizzard2020</td>\n",
       "      <td>door</td>\n",
       "      <td>blizzard</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>update</td>\n",
       "      <td>nlwx nltraffic</td>\n",
       "      <td>storm</td>\n",
       "      <td>food</td>\n",
       "      <td>nlwx</td>\n",
       "      <td>warning</td>\n",
       "      <td>street</td>\n",
       "      <td>snowpocalypse2020</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blizzard</td>\n",
       "      <td>nlwx nlblizzard2020</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>john</td>\n",
       "      <td>hoping</td>\n",
       "      <td>emergency</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>snowmageddon</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            topic 0              topic 1       topic 2       topic 3  \\\n",
       "0              nlwx                 nlwx         power    assistance   \n",
       "1              snow       nlblizzard2020          road  newfoundland   \n",
       "2      newfoundland         newfoundland          nlwx        people   \n",
       "3             storm     snowmaggedon2020  power outage     emergency   \n",
       "4              wind            nltraffic          john          nlwx   \n",
       "5         emergency          nlstorm2020          snow       helping   \n",
       "6  stormageddon2020         snowmageddon     emergency       support   \n",
       "7              john                 snow        closed     community   \n",
       "8            update       nlwx nltraffic         storm          food   \n",
       "9          blizzard  nlwx nlblizzard2020  newfoundland          john   \n",
       "\n",
       "          topic 4                         topic 5       topic 6  \\\n",
       "0          prayer                       stay safe          nlwx   \n",
       "1            hope                            nlwx          snow   \n",
       "2    newfoundland                    newfoundland           car   \n",
       "3  nlblizzard2020                            safe        people   \n",
       "4       stay safe                           storm         house   \n",
       "5        thinking                blizzard warning          john   \n",
       "6            safe  envcanada advisory blowingsnow          road   \n",
       "7       hope safe                  nlblizzard2020          door   \n",
       "8            nlwx                         warning        street   \n",
       "9          hoping                       emergency  newfoundland   \n",
       "\n",
       "             topic 7           topic 8  \n",
       "0               nlwx              nlwx  \n",
       "1               snow      newfoundland  \n",
       "2   snowmaggedon2020  snowmaggedon2020  \n",
       "3   stormageddon2020    nlblizzard2020  \n",
       "4       newfoundland              snow  \n",
       "5              storm               day  \n",
       "6     nlblizzard2020              time  \n",
       "7           blizzard            people  \n",
       "8  snowpocalypse2020              love  \n",
       "9       snowmageddon               dog  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_tfidf = topics_df(\n",
    "    topics = n_topics,\n",
    "    components = components_tfidf,\n",
    "    n_words = 10)\n",
    "\n",
    "pickle.dump(topics_tfidf, open(\"topics_sent_embed_tfidf.pickle\", \"wb\"))\n",
    "topics_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic 0</th>\n",
       "      <th>topic 1</th>\n",
       "      <th>topic 2</th>\n",
       "      <th>topic 3</th>\n",
       "      <th>topic 4</th>\n",
       "      <th>topic 5</th>\n",
       "      <th>topic 6</th>\n",
       "      <th>topic 7</th>\n",
       "      <th>topic 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snow</td>\n",
       "      <td>nlwx</td>\n",
       "      <td>power</td>\n",
       "      <td>assistance</td>\n",
       "      <td>hope</td>\n",
       "      <td>stay safe</td>\n",
       "      <td>snow</td>\n",
       "      <td>snow</td>\n",
       "      <td>newfoundland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>storm</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>road</td>\n",
       "      <td>people</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>safe</td>\n",
       "      <td>people</td>\n",
       "      <td>stormageddon2020</td>\n",
       "      <td>nlwx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newfoundland</td>\n",
       "      <td>nlblizzard2020</td>\n",
       "      <td>closed</td>\n",
       "      <td>helping</td>\n",
       "      <td>prayer</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>car</td>\n",
       "      <td>snowmaggedon2020</td>\n",
       "      <td>snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emergency</td>\n",
       "      <td>snowmaggedon2020</td>\n",
       "      <td>power outage</td>\n",
       "      <td>emergency</td>\n",
       "      <td>hoping</td>\n",
       "      <td>storm</td>\n",
       "      <td>storm</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>snowmaggedon2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stormageddon2020</td>\n",
       "      <td>nltraffic</td>\n",
       "      <td>snow</td>\n",
       "      <td>support</td>\n",
       "      <td>thinking</td>\n",
       "      <td>nlwx</td>\n",
       "      <td>power</td>\n",
       "      <td>storm</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wind</td>\n",
       "      <td>snow</td>\n",
       "      <td>emergency</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>stay safe</td>\n",
       "      <td>warning</td>\n",
       "      <td>nlwx</td>\n",
       "      <td>blizzard</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blizzard</td>\n",
       "      <td>nlstorm2020</td>\n",
       "      <td>storm</td>\n",
       "      <td>community</td>\n",
       "      <td>safe</td>\n",
       "      <td>stay</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>nlwx</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nlwx</td>\n",
       "      <td>snowmageddon</td>\n",
       "      <td>outage</td>\n",
       "      <td>food</td>\n",
       "      <td>hope safe</td>\n",
       "      <td>envcanada advisory blowingsnow</td>\n",
       "      <td>road</td>\n",
       "      <td>snowstorm</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>john</td>\n",
       "      <td>nlstorm</td>\n",
       "      <td>john</td>\n",
       "      <td>supply</td>\n",
       "      <td>storm</td>\n",
       "      <td>emergency</td>\n",
       "      <td>house</td>\n",
       "      <td>snowpocalypse2020</td>\n",
       "      <td>nlblizzard2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>update</td>\n",
       "      <td>snowstorm</td>\n",
       "      <td>lost power</td>\n",
       "      <td>service</td>\n",
       "      <td>friend</td>\n",
       "      <td>blizzard warning</td>\n",
       "      <td>door</td>\n",
       "      <td>winter</td>\n",
       "      <td>storm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            topic 0           topic 1       topic 2       topic 3  \\\n",
       "0              snow              nlwx         power    assistance   \n",
       "1             storm      newfoundland          road        people   \n",
       "2      newfoundland    nlblizzard2020        closed       helping   \n",
       "3         emergency  snowmaggedon2020  power outage     emergency   \n",
       "4  stormageddon2020         nltraffic          snow       support   \n",
       "5              wind              snow     emergency  newfoundland   \n",
       "6          blizzard       nlstorm2020         storm     community   \n",
       "7              nlwx      snowmageddon        outage          food   \n",
       "8              john           nlstorm          john        supply   \n",
       "9            update         snowstorm    lost power       service   \n",
       "\n",
       "        topic 4                         topic 5       topic 6  \\\n",
       "0          hope                       stay safe          snow   \n",
       "1  newfoundland                            safe        people   \n",
       "2        prayer                    newfoundland           car   \n",
       "3        hoping                           storm         storm   \n",
       "4      thinking                            nlwx         power   \n",
       "5     stay safe                         warning          nlwx   \n",
       "6          safe                            stay  newfoundland   \n",
       "7     hope safe  envcanada advisory blowingsnow          road   \n",
       "8         storm                       emergency         house   \n",
       "9        friend                blizzard warning          door   \n",
       "\n",
       "             topic 7           topic 8  \n",
       "0               snow      newfoundland  \n",
       "1   stormageddon2020              nlwx  \n",
       "2   snowmaggedon2020              snow  \n",
       "3       newfoundland  snowmaggedon2020  \n",
       "4              storm            people  \n",
       "5           blizzard              love  \n",
       "6               nlwx               day  \n",
       "7          snowstorm              time  \n",
       "8  snowpocalypse2020    nlblizzard2020  \n",
       "9             winter             storm  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_tfidf_attn = topics_df(\n",
    "    topics = n_topics,\n",
    "    components = components_tfidf_attn,\n",
    "    n_words = 10)\n",
    "\n",
    "pickle.dump(topics_tfidf_attn, open(\"topics_sent_embed_tfidf_attn.pickle\", \"wb\"))\n",
    "topics_tfidf_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Allen NLP",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
