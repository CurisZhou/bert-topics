{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from BertTM import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', )\n",
    "model = BertForSequenceClassificationOutputPooled.from_pretrained('bert-base-uncased', \n",
    "                                                              output_attentions=True, \n",
    "                                                              output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../bert-classifier-pytorch/model_save_attention_1epoch\"\n",
    "\n",
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "model = BertForSequenceClassificationOutputPooled.from_pretrained(output_dir,\n",
    "                                                      output_attentions = True, \n",
    "                                                      output_hidden_states = True)\n",
    "tokenizer = BertTokenizer.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "token_list = []\n",
    "cls_ = '[CLS]'\n",
    "sep_ = '[SEP]'\n",
    "sentences = ['Hello, my dog is cute and cutest.', 'I am too']\n",
    "for i, sent in enumerate(sentences):\n",
    "    inputs = tokenizer.encode_plus(sentences[i], add_special_tokens=True)\n",
    "    tokens = [cls_] + tokenizer.tokenize(sentences[i]) + [sep_]\n",
    "    input_ids = torch.tensor(inputs['input_ids']).unsqueeze(0)\n",
    "    input_list.append(input_ids)\n",
    "    token_list.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sentence embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_model = models.BERT(output_dir, max_seq_length = 240,)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "st_model = SentenceTransformer(modules=[word_embedding_model, pooling_model],\n",
    "                               #device=torch.device(\"cuda\")\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test that attention and vectorization work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentions = get_attention(sentences, model, tokenizer, method = 'first')\n",
    "np.sum([tpl[1] for tpl in attentions[1]])\n",
    "\n",
    "vectorized = vectorize(sentences, model, tokenizer)\n",
    "torch.stack(vectorized).detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('this', 0.0613682),\n",
       "  ('movie', 0.030429687),\n",
       "  ('was', 0.035641603),\n",
       "  ('the', 0.21911351),\n",
       "  ('cutest', 0.06270852),\n",
       "  ('.', 0.09440403),\n",
       "  ('read', 0.0423442),\n",
       "  ('more', 0.06480052),\n",
       "  ('at', 0.06262489),\n",
       "  ('http', 0.027938599),\n",
       "  (':', 0.043154325),\n",
       "  ('/', 0.038011733),\n",
       "  ('/', 0.041409045),\n",
       "  ('worstever', 0.04187157),\n",
       "  ('.', 0.08471608),\n",
       "  ('com', 0.049463503)]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_attention([\"this movie was the cutest. read more at http://worstever.com\"], model, tokenizer, method = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Model from BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nlwx_2020_hashtags_no_rt_predictions.csv\")\n",
    "data = df['text']\n",
    "ngram = (1, 3)\n",
    "n_topics = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 rows in 0.15 seconds.\n",
      "Processed 500 rows in 98.27 seconds.\n",
      "Processed 1000 rows in 193.77 seconds.\n",
      "Processed 1500 rows in 290.81 seconds.\n",
      "Processed 2000 rows in 386.74 seconds.\n",
      "Processed 2500 rows in 484.5 seconds.\n",
      "Processed 3000 rows in 584.24 seconds.\n",
      "Processed 3500 rows in 679.84 seconds.\n",
      "Processed 4000 rows in 776.88 seconds.\n",
      "Processed 4500 rows in 873.04 seconds.\n",
      "Processed 5000 rows in 969.55 seconds.\n",
      "Processed 5500 rows in 1067.45 seconds.\n",
      "Processed 6000 rows in 1168.92 seconds.\n",
      "Processed 6500 rows in 1268.35 seconds.\n",
      "Processed 7000 rows in 1366.79 seconds.\n",
      "Processed 7500 rows in 1468.06 seconds.\n",
      "Processed 8000 rows in 1570.23 seconds.\n",
      "Processed 8500 rows in 1671.15 seconds.\n",
      "Processed 9000 rows in 1772.01 seconds.\n",
      "Processed 9500 rows in 1872.32 seconds.\n",
      "Processed 10000 rows in 1970.01 seconds.\n",
      "Processed 10500 rows in 2071.37 seconds.\n",
      "Processed 11000 rows in 2172.99 seconds.\n",
      "Processed 11500 rows in 2273.16 seconds.\n",
      "Processed 12000 rows in 2370.85 seconds.\n",
      "Processed 12500 rows in 2469.11 seconds.\n",
      "Processed 13000 rows in 2567.32 seconds.\n",
      "Processed 13500 rows in 2668.98 seconds.\n",
      "Processed 14000 rows in 2772.43 seconds.\n",
      "Processed 14500 rows in 2876.16 seconds.\n",
      "Processed 15000 rows in 2975.96 seconds.\n",
      "Processed 15500 rows in 3077.56 seconds.\n",
      "Processed 16000 rows in 3179.27 seconds.\n",
      "Processed 16500 rows in 3279.89 seconds.\n",
      "Processed 17000 rows in 3381.93 seconds.\n",
      "Processed 17500 rows in 3483.49 seconds.\n",
      "Processed 18000 rows in 3584.39 seconds.\n",
      "Processed 18500 rows in 3688.12 seconds.\n",
      "Processed 19000 rows in 3790.6 seconds.\n",
      "Processed 19500 rows in 3891.36 seconds.\n",
      "Processed 20000 rows in 3987.45 seconds.\n",
      "Processed 20500 rows in 4084.35 seconds.\n",
      "Processed 21000 rows in 4185.52 seconds.\n",
      "Processed 21500 rows in 4286.16 seconds.\n",
      "CPU times: user 1h 11min 51s, sys: 28.7 s, total: 1h 12min 20s\n",
      "Wall time: 1h 12min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rows, attentions = get_embeddings(data, model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data after creating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_data = []\n",
    "\n",
    "for i in range(len(rows)):\n",
    "    all_model_data.append((data[i], df.prediction[i], attentions[i], rows[i]))\n",
    "    \n",
    "#pickle.dump(all_model_data, open(f\"attentions_sent_embeddings.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1325\n"
     ]
    }
   ],
   "source": [
    "extended_stopwords = ['#', '@', '…', \"'\", \"’\", \"[UNK]\", \"\\\"\", \";\", \"*\", \"_\", \"amp\", \"&\", \"“\", \"”\",\n",
    "                      'nlwhiteout', 'nlweather', 'newfoundland', 'nlblizzard2020', 'nlstorm2020',\n",
    "                      'snowmaggedon2020', 'stormageddon2020', 'snowpocalypse2020', 'snowmageddon',\n",
    "                      'nlstorm', 'nltraffic', 'nlwx', 'nlblizzard']\n",
    "stopwords = get_stopwords(extended_stopwords)\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pickled embedding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_data = pickle.load(open(\"attentions_sent_embeddings.pkl\", \"rb\"))\n",
    "texts, _, attentions, rows = zip(*all_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train kmeans model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting kmeans model.\n",
      "The number of texts per label are:\n",
      "{0: 2632, 1: 4438, 2: 1034, 3: 826, 4: 670, 5: 798, 6: 2858, 7: 4467, 8: 4074}\n",
      "CPU times: user 37.4 s, sys: 2 s, total: 39.4 s\n",
      "Wall time: 33.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "labels = get_clusters(rows, n_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop stopwords and empty documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering attentions.\n",
      "CPU times: user 11.8 s, sys: 0 ns, total: 11.8 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "  \n",
    "filtered_a, filtered_t, filtered_l = filter_data(attentions, stopwords, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Gensim's phraser to determine which ngram to include a word in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.66 s, sys: 0 ns, total: 4.66 s\n",
      "Wall time: 4.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "features = get_phrases(filtered_t, min_count=10, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use BERT's attention mechanism to determine which words characterize each kmeans cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Determining cluster components. This will take awhile. \n",
      "Progress will be printed for every 500th processed property.\n",
      "    \n",
      "Processed 5000 texts in 1.65 seconds.\n",
      "Processed 10000 texts in 3.31 seconds.\n",
      "Processed 15000 texts in 5.05 seconds.\n",
      "Processed 20000 texts in 6.89 seconds.\n",
      "Finished determining a total of 21755 cluster components. Total time 7.46 seconds.\n",
      "CPU times: user 7.45 s, sys: 8 ms, total: 7.46 s\n",
      "Wall time: 7.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "components, words_label = determine_cluster_components(filtered_l, filtered_a, ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use term frequency inverse cluster frequency with and without BERT's attentions mechanism to determine which words characterize each kmeans cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 352 ms, sys: 0 ns, total: 352 ms\n",
      "Wall time: 350 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_indexed = tf_icf(words_label, n_topics)\n",
    "components_tfidf, components_tfidf_attn = get_tfidf_components(components, tfidf_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_attn = topics_df(\n",
    "    topics = n_topics,\n",
    "    components = components,\n",
    "    n_words = 10)\n",
    "\n",
    "#pickle.dump(topics_attn, open(\"topics_sent_embed.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic 0</th>\n",
       "      <th>topic 1</th>\n",
       "      <th>topic 2</th>\n",
       "      <th>topic 3</th>\n",
       "      <th>topic 4</th>\n",
       "      <th>topic 5</th>\n",
       "      <th>topic 6</th>\n",
       "      <th>topic 7</th>\n",
       "      <th>topic 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snow</td>\n",
       "      <td>snowmageddon2020</td>\n",
       "      <td>power</td>\n",
       "      <td>assistance</td>\n",
       "      <td>hope</td>\n",
       "      <td>stay safe</td>\n",
       "      <td>snow</td>\n",
       "      <td>snow</td>\n",
       "      <td>snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>storm</td>\n",
       "      <td>snow</td>\n",
       "      <td>closed</td>\n",
       "      <td>helping</td>\n",
       "      <td>thinking</td>\n",
       "      <td>safe</td>\n",
       "      <td>storm</td>\n",
       "      <td>storm</td>\n",
       "      <td>storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emergency</td>\n",
       "      <td>snowstorm</td>\n",
       "      <td>power outage</td>\n",
       "      <td>people</td>\n",
       "      <td>hoping</td>\n",
       "      <td>warning</td>\n",
       "      <td>people</td>\n",
       "      <td>blizzard</td>\n",
       "      <td>shovel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blizzard</td>\n",
       "      <td>blizzard</td>\n",
       "      <td>road</td>\n",
       "      <td>support</td>\n",
       "      <td>stay safe</td>\n",
       "      <td>storm</td>\n",
       "      <td>power</td>\n",
       "      <td>snowstorm</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wind</td>\n",
       "      <td>nlsnowstorm2020</td>\n",
       "      <td>snow</td>\n",
       "      <td>emergency</td>\n",
       "      <td>prayer</td>\n",
       "      <td>stay</td>\n",
       "      <td>car</td>\n",
       "      <td>weather</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>snowfall</td>\n",
       "      <td>canada</td>\n",
       "      <td>storm</td>\n",
       "      <td>supply</td>\n",
       "      <td>safe</td>\n",
       "      <td>emergency</td>\n",
       "      <td>digging</td>\n",
       "      <td>winter</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weather</td>\n",
       "      <td>love</td>\n",
       "      <td>emergency</td>\n",
       "      <td>community</td>\n",
       "      <td>storm</td>\n",
       "      <td>envcanada advisory blowingsnow</td>\n",
       "      <td>buried</td>\n",
       "      <td>blizzard2020</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>update</td>\n",
       "      <td>storm</td>\n",
       "      <td>lost power</td>\n",
       "      <td>food</td>\n",
       "      <td>friend</td>\n",
       "      <td>stay safe warm</td>\n",
       "      <td>missing</td>\n",
       "      <td>snowmageddon2020</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>john</td>\n",
       "      <td>wow</td>\n",
       "      <td>outage</td>\n",
       "      <td>snow</td>\n",
       "      <td>god</td>\n",
       "      <td>alert</td>\n",
       "      <td>stuck</td>\n",
       "      <td>newfoundlandstorm</td>\n",
       "      <td>neighbour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>forecast</td>\n",
       "      <td>crazy</td>\n",
       "      <td>damage</td>\n",
       "      <td>service</td>\n",
       "      <td>people</td>\n",
       "      <td>snow</td>\n",
       "      <td>emergency</td>\n",
       "      <td>wind</td>\n",
       "      <td>newfoundlanders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic 0           topic 1       topic 2     topic 3    topic 4  \\\n",
       "0       snow  snowmageddon2020         power  assistance       hope   \n",
       "1      storm              snow        closed     helping   thinking   \n",
       "2  emergency         snowstorm  power outage      people     hoping   \n",
       "3   blizzard          blizzard          road     support  stay safe   \n",
       "4       wind   nlsnowstorm2020          snow   emergency     prayer   \n",
       "5   snowfall            canada         storm      supply       safe   \n",
       "6    weather              love     emergency   community      storm   \n",
       "7     update             storm    lost power        food     friend   \n",
       "8       john               wow        outage        snow        god   \n",
       "9   forecast             crazy        damage     service     people   \n",
       "\n",
       "                          topic 5    topic 6            topic 7  \\\n",
       "0                       stay safe       snow               snow   \n",
       "1                            safe      storm              storm   \n",
       "2                         warning     people           blizzard   \n",
       "3                           storm      power          snowstorm   \n",
       "4                            stay        car            weather   \n",
       "5                       emergency    digging             winter   \n",
       "6  envcanada advisory blowingsnow     buried       blizzard2020   \n",
       "7                  stay safe warm    missing   snowmageddon2020   \n",
       "8                           alert      stuck  newfoundlandstorm   \n",
       "9                            snow  emergency               wind   \n",
       "\n",
       "           topic 8  \n",
       "0             snow  \n",
       "1            storm  \n",
       "2           shovel  \n",
       "3             love  \n",
       "4           people  \n",
       "5              day  \n",
       "6             hope  \n",
       "7              dog  \n",
       "8        neighbour  \n",
       "9  newfoundlanders  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic 0</th>\n",
       "      <th>topic 1</th>\n",
       "      <th>topic 2</th>\n",
       "      <th>topic 3</th>\n",
       "      <th>topic 4</th>\n",
       "      <th>topic 5</th>\n",
       "      <th>topic 6</th>\n",
       "      <th>topic 7</th>\n",
       "      <th>topic 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snow</td>\n",
       "      <td>snowmageddon2020</td>\n",
       "      <td>power</td>\n",
       "      <td>assistance</td>\n",
       "      <td>prayer</td>\n",
       "      <td>stay safe</td>\n",
       "      <td>snow</td>\n",
       "      <td>snow</td>\n",
       "      <td>snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>storm</td>\n",
       "      <td>snow</td>\n",
       "      <td>road</td>\n",
       "      <td>people</td>\n",
       "      <td>hope</td>\n",
       "      <td>safe</td>\n",
       "      <td>car</td>\n",
       "      <td>storm</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wind</td>\n",
       "      <td>cbcnl</td>\n",
       "      <td>john</td>\n",
       "      <td>emergency</td>\n",
       "      <td>stay safe</td>\n",
       "      <td>storm</td>\n",
       "      <td>people</td>\n",
       "      <td>blizzard</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>john</td>\n",
       "      <td>canada</td>\n",
       "      <td>power outage</td>\n",
       "      <td>helping</td>\n",
       "      <td>thinking</td>\n",
       "      <td>blizzard warning</td>\n",
       "      <td>john</td>\n",
       "      <td>snowmageddon2020</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emergency</td>\n",
       "      <td>snowstorm</td>\n",
       "      <td>snow</td>\n",
       "      <td>support</td>\n",
       "      <td>hope safe</td>\n",
       "      <td>envcanada advisory blowingsnow</td>\n",
       "      <td>road</td>\n",
       "      <td>snowstorm</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blizzard</td>\n",
       "      <td>nlsnowstorm2020</td>\n",
       "      <td>emergency</td>\n",
       "      <td>john</td>\n",
       "      <td>safe</td>\n",
       "      <td>warning</td>\n",
       "      <td>house</td>\n",
       "      <td>winter</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>update</td>\n",
       "      <td>yytsoe</td>\n",
       "      <td>closed</td>\n",
       "      <td>community</td>\n",
       "      <td>people</td>\n",
       "      <td>emergency</td>\n",
       "      <td>door</td>\n",
       "      <td>day</td>\n",
       "      <td>snowmageddon2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day</td>\n",
       "      <td>john</td>\n",
       "      <td>storm</td>\n",
       "      <td>food</td>\n",
       "      <td>friend</td>\n",
       "      <td>stay safe warm</td>\n",
       "      <td>street</td>\n",
       "      <td>john</td>\n",
       "      <td>john</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weather</td>\n",
       "      <td>day</td>\n",
       "      <td>street</td>\n",
       "      <td>supply</td>\n",
       "      <td>hoping</td>\n",
       "      <td>snow</td>\n",
       "      <td>power</td>\n",
       "      <td>blizzard2020</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>canada</td>\n",
       "      <td>snowmegeddon2020</td>\n",
       "      <td>outage</td>\n",
       "      <td>snow</td>\n",
       "      <td>storm</td>\n",
       "      <td>stay</td>\n",
       "      <td>storm</td>\n",
       "      <td>weather</td>\n",
       "      <td>даниила егорова pin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic 0           topic 1       topic 2     topic 3    topic 4  \\\n",
       "0       snow  snowmageddon2020         power  assistance     prayer   \n",
       "1      storm              snow          road      people       hope   \n",
       "2       wind             cbcnl          john   emergency  stay safe   \n",
       "3       john            canada  power outage     helping   thinking   \n",
       "4  emergency         snowstorm          snow     support  hope safe   \n",
       "5   blizzard   nlsnowstorm2020     emergency        john       safe   \n",
       "6     update            yytsoe        closed   community     people   \n",
       "7        day              john         storm        food     friend   \n",
       "8    weather               day        street      supply     hoping   \n",
       "9     canada  snowmegeddon2020        outage        snow      storm   \n",
       "\n",
       "                          topic 5 topic 6           topic 7  \\\n",
       "0                       stay safe    snow              snow   \n",
       "1                            safe     car             storm   \n",
       "2                           storm  people          blizzard   \n",
       "3                blizzard warning    john  snowmageddon2020   \n",
       "4  envcanada advisory blowingsnow    road         snowstorm   \n",
       "5                         warning   house            winter   \n",
       "6                       emergency    door               day   \n",
       "7                  stay safe warm  street              john   \n",
       "8                            snow   power      blizzard2020   \n",
       "9                            stay   storm           weather   \n",
       "\n",
       "               topic 8  \n",
       "0                 snow  \n",
       "1                  day  \n",
       "2                 time  \n",
       "3               people  \n",
       "4                 love  \n",
       "5                  dog  \n",
       "6     snowmageddon2020  \n",
       "7                 john  \n",
       "8              morning  \n",
       "9  даниила егорова pin  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_tfidf = topics_df(\n",
    "    topics = n_topics,\n",
    "    components = components_tfidf,\n",
    "    n_words = 10)\n",
    "\n",
    "topics_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic 0</th>\n",
       "      <th>topic 1</th>\n",
       "      <th>topic 2</th>\n",
       "      <th>topic 3</th>\n",
       "      <th>topic 4</th>\n",
       "      <th>topic 5</th>\n",
       "      <th>topic 6</th>\n",
       "      <th>topic 7</th>\n",
       "      <th>topic 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snow</td>\n",
       "      <td>snowmageddon2020</td>\n",
       "      <td>power</td>\n",
       "      <td>assistance</td>\n",
       "      <td>hope</td>\n",
       "      <td>stay safe</td>\n",
       "      <td>snow</td>\n",
       "      <td>snow</td>\n",
       "      <td>snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>storm</td>\n",
       "      <td>snow</td>\n",
       "      <td>road</td>\n",
       "      <td>people</td>\n",
       "      <td>thinking</td>\n",
       "      <td>safe</td>\n",
       "      <td>people</td>\n",
       "      <td>storm</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emergency</td>\n",
       "      <td>snowstorm</td>\n",
       "      <td>closed</td>\n",
       "      <td>helping</td>\n",
       "      <td>prayer</td>\n",
       "      <td>storm</td>\n",
       "      <td>car</td>\n",
       "      <td>blizzard</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wind</td>\n",
       "      <td>canada</td>\n",
       "      <td>power outage</td>\n",
       "      <td>emergency</td>\n",
       "      <td>stay safe</td>\n",
       "      <td>warning</td>\n",
       "      <td>storm</td>\n",
       "      <td>snowstorm</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blizzard</td>\n",
       "      <td>nlsnowstorm2020</td>\n",
       "      <td>snow</td>\n",
       "      <td>support</td>\n",
       "      <td>hoping</td>\n",
       "      <td>stay</td>\n",
       "      <td>power</td>\n",
       "      <td>snowmageddon2020</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>john</td>\n",
       "      <td>love</td>\n",
       "      <td>storm</td>\n",
       "      <td>community</td>\n",
       "      <td>safe</td>\n",
       "      <td>envcanada advisory blowingsnow</td>\n",
       "      <td>road</td>\n",
       "      <td>winter</td>\n",
       "      <td>storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>update</td>\n",
       "      <td>day</td>\n",
       "      <td>emergency</td>\n",
       "      <td>food</td>\n",
       "      <td>hope safe</td>\n",
       "      <td>emergency</td>\n",
       "      <td>door</td>\n",
       "      <td>weather</td>\n",
       "      <td>shovel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>snowfall</td>\n",
       "      <td>blizzard</td>\n",
       "      <td>outage</td>\n",
       "      <td>supply</td>\n",
       "      <td>friend</td>\n",
       "      <td>blizzard warning</td>\n",
       "      <td>house</td>\n",
       "      <td>blizzard2020</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weather</td>\n",
       "      <td>john</td>\n",
       "      <td>john</td>\n",
       "      <td>snow</td>\n",
       "      <td>people</td>\n",
       "      <td>stay safe warm</td>\n",
       "      <td>street</td>\n",
       "      <td>day</td>\n",
       "      <td>neighbour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day</td>\n",
       "      <td>wow</td>\n",
       "      <td>lost power</td>\n",
       "      <td>service</td>\n",
       "      <td>storm</td>\n",
       "      <td>snow</td>\n",
       "      <td>john</td>\n",
       "      <td>newfoundlandstorm</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic 0           topic 1       topic 2     topic 3    topic 4  \\\n",
       "0       snow  snowmageddon2020         power  assistance       hope   \n",
       "1      storm              snow          road      people   thinking   \n",
       "2  emergency         snowstorm        closed     helping     prayer   \n",
       "3       wind            canada  power outage   emergency  stay safe   \n",
       "4   blizzard   nlsnowstorm2020          snow     support     hoping   \n",
       "5       john              love         storm   community       safe   \n",
       "6     update               day     emergency        food  hope safe   \n",
       "7   snowfall          blizzard        outage      supply     friend   \n",
       "8    weather              john          john        snow     people   \n",
       "9        day               wow    lost power     service      storm   \n",
       "\n",
       "                          topic 5 topic 6            topic 7    topic 8  \n",
       "0                       stay safe    snow               snow       snow  \n",
       "1                            safe  people              storm     people  \n",
       "2                           storm     car           blizzard       love  \n",
       "3                         warning   storm          snowstorm        day  \n",
       "4                            stay   power   snowmageddon2020       time  \n",
       "5  envcanada advisory blowingsnow    road             winter      storm  \n",
       "6                       emergency    door            weather     shovel  \n",
       "7                blizzard warning   house       blizzard2020        dog  \n",
       "8                  stay safe warm  street                day  neighbour  \n",
       "9                            snow    john  newfoundlandstorm     friend  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_tfidf_attn = topics_df(\n",
    "    topics = n_topics,\n",
    "    components = components_tfidf_attn,\n",
    "    n_words = 10)\n",
    "\n",
    "topics_tfidf_attn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Allen NLP",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
